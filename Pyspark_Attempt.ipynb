{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial import and starting the spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some pandas functionality we didn't end up using\n",
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the spark session??\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"RecommendationEngine\").config(\"spark.driver.host\",\"localhost\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=858, rating=4, timestamp=956678732.0, user_id=6040),\n",
       " Row(movie_id=2384, rating=4, timestamp=956678754.0, user_id=6040),\n",
       " Row(movie_id=593, rating=5, timestamp=956678754.0, user_id=6040),\n",
       " Row(movie_id=1961, rating=4, timestamp=956678777.0, user_id=6040),\n",
       " Row(movie_id=1419, rating=3, timestamp=956678856.0, user_id=6040),\n",
       " Row(movie_id=213, rating=5, timestamp=956678856.0, user_id=6040),\n",
       " Row(movie_id=3111, rating=5, timestamp=956678856.0, user_id=6040),\n",
       " Row(movie_id=573, rating=4, timestamp=956678856.0, user_id=6040),\n",
       " Row(movie_id=3505, rating=4, timestamp=956678856.0, user_id=6040),\n",
       " Row(movie_id=1734, rating=2, timestamp=956678881.0, user_id=6040)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the first json file, ratings\n",
    "ratings = spark.read.json(\"data/ratings.json\")\n",
    "ratings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(movie_id=858, rating=4, timestamp=956678732.0, user_id=6040)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the ratings by movie_id, to arrive at the average movie rating\n",
    "# This is the most basic iteration, an unweighted average rating\n",
    "\n",
    "grouped = ratings.groupby([\"movie_id\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(movie_id=26, avg(movie_id)=26.0, avg(rating)=3.4788732394366195, avg(timestamp)=967825426.5070423, avg(user_id)=3564.774647887324)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=3881, avg(movie_id)=3881.0, avg(rating)=5.0, avg(timestamp)=972427747.0, avg(user_id)=2885.0),\n",
       " Row(movie_id=2964, avg(movie_id)=2964.0, avg(rating)=5.0, avg(timestamp)=962393248.0, avg(user_id)=5077.0),\n",
       " Row(movie_id=1830, avg(movie_id)=1830.0, avg(rating)=5.0, avg(timestamp)=972413840.0, avg(user_id)=2869.0),\n",
       " Row(movie_id=3607, avg(movie_id)=3607.0, avg(rating)=5.0, avg(timestamp)=957731408.0, avg(user_id)=5851.0),\n",
       " Row(movie_id=3522, avg(movie_id)=3522.0, avg(rating)=5.0, avg(timestamp)=959108978.0, avg(user_id)=5616.0),\n",
       " Row(movie_id=3656, avg(movie_id)=3656.0, avg(rating)=5.0, avg(timestamp)=960895192.0, avg(user_id)=5313.0),\n",
       " Row(movie_id=3233, avg(movie_id)=3233.0, avg(rating)=5.0, avg(timestamp)=966399373.5, avg(user_id)=3733.0),\n",
       " Row(movie_id=3382, avg(movie_id)=3382.0, avg(rating)=5.0, avg(timestamp)=960770959.0, avg(user_id)=5334.0),\n",
       " Row(movie_id=1471, avg(movie_id)=1471.0, avg(rating)=5.0, avg(timestamp)=975243157.0, avg(user_id)=1896.0),\n",
       " Row(movie_id=787, avg(movie_id)=787.0, avg(rating)=5.0, avg(timestamp)=972491689.5, avg(user_id)=2848.5)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting to find the movies with the highest average rating\n",
    "grouped.sort(grouped[\"avg(rating)\"].desc()).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted(grouped, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a clean ratings dataframe, without the timestamp column\n",
    "clean_ratings = ratings.drop(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(movie_id=858, rating=4, user_id=6040)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New imports! The recommendation engine and an evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a train/test split of our clean ratings dataframe\n",
    "(train, test) = clean_ratings.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating our recommendation model, with just default hyperparameters\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"movie_id\",\n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Fitting the recommendation model as our base model (since it's so basic)\n",
    "base_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.8756899586123921\n"
     ]
    }
   ],
   "source": [
    "# Arriving at predictions for our test data\n",
    "base_preds = base_model.transform(test)\n",
    "\n",
    "# Initiating our evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Actually using our evaluator, and arriving at the RMSE\n",
    "base_rmse = evaluator.evaluate(base_preds)\n",
    "print(\"Root Mean Squared Error: \" + str(base_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RMSE of nearly 1 is pretty bad - means that the average prediction is nearly one star off, out of five. But this is the baseline we'll try to improve upon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More imports\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Initiating a new recommendation model\n",
    "als_tuned = ALS(userCol=\"user_id\", itemCol=\"movie_id\",\n",
    "                ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Setting up our parameter grid, to try different hyperparameters\n",
    "params = ParamGridBuilder().addGrid(als_tuned.regParam, [0.01, 0.001, 0.1]).addGrid(\n",
    "    als_tuned.rank, [4, 10, 50]).build()\n",
    "\n",
    "# instantiating crossvalidator estimator, \n",
    "cv = CrossValidator(estimator=als_tuned, estimatorParamMaps=params,\n",
    "                    evaluator=evaluator, parallelism=4)\n",
    "\n",
    "best_model = cv.fit(ratings)\n",
    "\n",
    "# This takes forever!\n",
    "best_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.8173528520014758\n"
     ]
    }
   ],
   "source": [
    "# Arriving at predictions for our test data for our newly-tuned model\n",
    "tuned_preds = best_model.transform(test)\n",
    "\n",
    "# Initiating our evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Actually using our evaluator, and arriving at the RMSE\n",
    "tuned_rmse = evaluator.evaluate(tuned_preds)\n",
    "print(\"Root Mean Squared Error: \" + str(tuned_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improvement! But only slight, and testing the parameter grid and using the cross validator together took probably 20 minutes. Not enough of an improvement to be worth that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
